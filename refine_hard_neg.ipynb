{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "subtle-translation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=2\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%env CUDA_VISIBLE_DEVICES=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "educational-statistics",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def set_seed(seed):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    \n",
    "    random.seed(seed)\n",
    "    \n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed) # if you are using multi-GPU.\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "def set_global_logging_level(level=logging.ERROR, prefixes=(\"\",)):\n",
    "    \"\"\"\n",
    "    Override logging levels of different modules based on their name as a prefix.\n",
    "    It needs to be invoked after the modules have been loaded so that their loggers have been initialized.\n",
    "\n",
    "    Args:\n",
    "        level: desired level. Optional. Default is logging.ERROR\n",
    "        prefixes: list of one or more str prefixes to match (e.g. [\"transformers\", \"torch\"]). Optional.\n",
    "            Default is `[\"\"]` to match all active loggers.\n",
    "            The match is a case-sensitive `module_name.startswith(prefix)`\n",
    "    \"\"\"\n",
    "    prefix_re = re.compile(fr'^(?:{\"|\".join(prefixes)})')\n",
    "    for name in logging.root.manager.loggerDict:\n",
    "        if re.match(prefix_re, name):\n",
    "            logging.getLogger(name).setLevel(level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "continuing-ending",
   "metadata": {},
   "outputs": [],
   "source": [
    "# logger = logging.getLogger()\n",
    "# logger.setLevel(logging.INFO)\n",
    "# if logger.hasHandlers():\n",
    "#     logger.handlers.clear()\n",
    "# console = logging.StreamHandler()\n",
    "# logger.addHandler(console)\n",
    "\n",
    "logging.basicConfig(\n",
    "    format='[%(asctime)s %(levelname)s %(name)s] %(message)s', datefmt='%m/%d %H:%M:%S',\n",
    "    level=logging.INFO\n",
    ")\n",
    "set_global_logging_level(logging.WARNING, [\"elasticsearch\"])\n",
    "\n",
    "set_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fuzzy-infection",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05/15 09:10:52 INFO transformers.file_utils] PyTorch version 1.4.0 available.\n",
      "[05/15 09:10:54 INFO transformers.configuration_utils] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/google/electra-base-discriminator/config.json from cache at /home/shenhuawei/.cache/torch/transformers/9236d197566a7f1be2b2151f5afcc5a8e17f31e1e23c52f3cdf2340019986e78.88ba6e8e7d5a7936e86d6f2551fe19c236dc57c24da163907cd0544e9933f6ee\n",
      "[05/15 09:10:54 INFO transformers.configuration_utils] Model config ElectraConfig {\n",
      "  \"architectures\": [\n",
      "    \"ElectraForPreTraining\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"embedding_size\": 768,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"electra\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"summary_activation\": \"gelu\",\n",
      "  \"summary_last_dropout\": 0.1,\n",
      "  \"summary_type\": \"first\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "[05/15 09:10:55 INFO transformers.tokenization_utils_base] loading file https://s3.amazonaws.com/models.huggingface.co/bert/google/electra-base-discriminator/vocab.txt from cache at /home/shenhuawei/.cache/torch/transformers/ff085885d4c95651587af553adadd34a26de8a663f2cef709635b48b3bed2bbd.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "[05/15 09:10:57 INFO transformers.configuration_utils] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/google/electra-large-discriminator/config.json from cache at /home/shenhuawei/.cache/torch/transformers/48566de2a306c9c19a25d6f10f39a6577305afa69c1bec8c1ad700c28e5e965b.001c8b19ce0ff318bfc661c6e98613a61d6a55b87644386ebe68d14d403d27ea\n",
      "[05/15 09:10:57 INFO transformers.configuration_utils] Model config ElectraConfig {\n",
      "  \"architectures\": [\n",
      "    \"ElectraForPreTraining\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"embedding_size\": 1024,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"electra\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"summary_activation\": \"gelu\",\n",
      "  \"summary_last_dropout\": 0.1,\n",
      "  \"summary_type\": \"first\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "[05/15 09:11:01 INFO transformers.modeling_utils] loading weights file https://cdn.huggingface.co/google/electra-large-discriminator/pytorch_model.bin from cache at /home/shenhuawei/.cache/torch/transformers/f186d2f61f70a4822a995a55c3252c0f3b4807f510c652145d448b2a62a73954.1bd04e37e803733865c2fe33919dde371c7c0300a972b35ff1cae57c02c7e9e4\n",
      "[05/15 09:11:10 WARNING transformers.modeling_utils] Some weights of the model checkpoint at google/electra-large-discriminator were not used when initializing ElectraModel: ['electra.embeddings_project.weight', 'electra.embeddings_project.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "[05/15 09:11:10 INFO transformers.modeling_utils] All the weights of ElectraModel were initialized from the model checkpoint at google/electra-large-discriminator.\n",
      "If your task is similar to the task the model of the ckeckpoint was trained on, you can already use ElectraModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoConfig, AutoTokenizer\n",
    "from models.reranker import Reranker\n",
    "from utils.model_utils import load_state\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('google/electra-base-discriminator', use_fast=True,\n",
    "                                          additional_special_tokens=['[unused0]', '[unused1]',\n",
    "                                                                     '[unused2]', '[unused3]'])\n",
    "reranker = Reranker('google/electra-large-discriminator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "minus-invite",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05/15 09:16:02 INFO utils.data_utils] Loaded 5232080 passages from data/corpus/hotpot-paragraph-5.tsv\n"
     ]
    }
   ],
   "source": [
    "from utils.data_utils import load_corpus\n",
    "\n",
    "corpus, title2id = load_corpus('data/corpus/hotpot-paragraph-5.tsv', for_hotpot=True, require_hyperlinks=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "weighted-louisiana",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from torch.utils.data import DataLoader\n",
    "from reranking_data import RerankingDataset, collate_qp\n",
    "\n",
    "split = 'dev'\n",
    "is_strict = True\n",
    "dataset = RerankingDataset(f\"data/hotpot-step-{split}{'.strict' if is_strict else ''}.jsonl\", tokenizer, corpus, title2id,\n",
    "                           max_seq_len=512, max_q_len=96, max_obs_len=256, strict=is_strict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "parallel-delivery",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "collate_func = partial(collate_qp, pad_id=tokenizer.pad_token_id)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, collate_fn=collate_func,\n",
    "                        pin_memory=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "substantial-designation",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reranker(\n",
       "  (encoder): ElectraModel(\n",
       "    (embeddings): ElectraEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 1024, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 1024)\n",
       "      (token_type_embeddings): Embedding(2, 1024)\n",
       "      (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (12): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (13): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (14): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (15): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (16): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (17): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (18): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (19): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (20): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (21): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (22): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (23): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (reranker): Linear(in_features=1024, out_features=1, bias=True)\n",
       "  (bce_loss): BCEWithLogitsLoss()\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "init_checkpoint = 'ckpts/td5-exp1-ila.4_electra-large-discriminator_DP0.5_HN2_M2_D2_adamW_SP0.5_B32_LR2.0e-05_WU0.1_E30_S42_04270247_pld-sb0-wo*-cmd10/checkpoint_pr.pt'\n",
    "reranker = load_state(reranker, init_checkpoint, strict=False)\n",
    "reranker.to(device)\n",
    "reranker.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "discrete-richards",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c417fb694444115ac2dc5616ced646d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=16408.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "from utils.tensor_utils import to_device\n",
    "\n",
    "para_scores = []\n",
    "reranker.eval()\n",
    "for batch in tqdm(dataloader):\n",
    "    nn_input = to_device(batch['nn_input'], device)\n",
    "    with torch.no_grad():\n",
    "        para_logits = reranker(nn_input)\n",
    "        para_probs = torch.cat(para_logits, dim=0).sigmoid()\n",
    "        para_scores.extend(para_probs.tolist())\n",
    "assert len(para_scores) == len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "approximate-quality",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-6e6df518a476>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "monetary-filling",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "em = 0.\n",
    "recall = 0.\n",
    "hit = 0.\n",
    "hn_nums = []\n",
    "refined_examples = []\n",
    "scored_examples = []\n",
    "with open(f\"data/hotpot-step-{split}{'.strict' if is_strict else ''}.refined.tmp.jsonl\", 'w') as f1, open(f\"data/hotpot-step-{split}{'.strict' if is_strict else ''}.scored.tmp.jsonl\", 'w') as f2:\n",
    "    for example in tqdm(dataset.examples):\n",
    "        pair_offset, num_pair = example['pair_offset'], example['num_pair']\n",
    "        sp_scores = []\n",
    "        for para_score in para_scores[pair_offset:pair_offset + 2]:\n",
    "            sp_scores.append(para_score)\n",
    "        hn_scores = []\n",
    "        for para_score in para_scores[pair_offset + 2:pair_offset + num_pair]:\n",
    "            hn_scores.append(para_score)\n",
    "        assert len(hn_scores) == len(example['hn_ids'])\n",
    "\n",
    "        min_sp_score = min(sp_scores)\n",
    "        sorted_hn_indices = sorted(list(range(len(hn_scores))), key=lambda idx: -hn_scores[idx])\n",
    "        refined_hn_ids, refined_hn_scores = [], []\n",
    "        for idx in sorted_hn_indices:\n",
    "            if len(refined_hn_ids) >= 30:\n",
    "                break\n",
    "            if len(refined_hn_ids) < 15 or hn_scores[idx] >= min(min_sp_score, 0.1):\n",
    "                refined_hn_ids.append(example['hn_ids'][idx])\n",
    "                refined_hn_scores.append(hn_scores[idx])\n",
    "            else:\n",
    "                break\n",
    "        hn_nums.append(len(refined_hn_ids))\n",
    "        assert 15 <= len(refined_hn_ids) == len(refined_hn_scores) <= 30\n",
    "        sorted_hn_ids, sorted_hn_scores = [], []\n",
    "        for idx in sorted_hn_indices:\n",
    "            sorted_hn_ids.append(example['hn_ids'][idx])\n",
    "            sorted_hn_scores.append(hn_scores[idx])\n",
    "\n",
    "#         if min_sp_score < 0.001:\n",
    "#             print(sp_scores)\n",
    "#         if len(refined_hn_ids) > 20:\n",
    "#             print(sp_scores)\n",
    "#             print(len(refined_hn_scores), refined_hn_scores)\n",
    "\n",
    "        if min_sp_score > refined_hn_scores[0]:\n",
    "            em += 1.\n",
    "            recall += 1.\n",
    "            hit += 1.\n",
    "        elif max(sp_scores) > refined_hn_scores[1]:\n",
    "            em += 0.\n",
    "            recall += 0.5\n",
    "            hit += 1.\n",
    "        else:\n",
    "            em += 0.\n",
    "            recall += 0.\n",
    "            hit += 0.\n",
    "\n",
    "        refined_example = {\n",
    "            \"_id\": example['_id'],\n",
    "            \"question\": example['question'],\n",
    "            \"answer\": example['answer'],\n",
    "            \"sp_facts\": example['sp_facts'],\n",
    "            \"sp_ids\": example['sp_ids'],\n",
    "            \"sp_scores\": sp_scores,\n",
    "            \"hard_negs\": refined_hn_ids,  # in- and out- neighbors of SPs, top ranked passages\n",
    "            \"hn_scores\": refined_hn_scores,\n",
    "            \"state2action\": example['state2action']\n",
    "        }\n",
    "        refined_examples.append(refined_example)\n",
    "        f1.write(json.dumps(refined_example, ensure_ascii=False) + '\\n')\n",
    "        \n",
    "        scored_example = {\n",
    "            \"_id\": example['_id'],\n",
    "            \"question\": example['question'],\n",
    "            \"answer\": example['answer'],\n",
    "            \"sp_facts\": example['sp_facts'],\n",
    "            \"sp_ids\": example['sp_ids'],\n",
    "            \"sp_scores\": sp_scores,\n",
    "            \"hard_negs\": sorted_hn_ids,  # in- and out- neighbors of SPs, top ranked passages\n",
    "            \"hn_scores\": sorted_hn_scores,\n",
    "            \"state2action\": example['state2action']\n",
    "        }\n",
    "        scored_examples.append(scored_example)\n",
    "        f2.write(json.dumps(scored_example, ensure_ascii=False) + '\\n')\n",
    "\n",
    "print(sum(hn_nums) / len(hn_nums))\n",
    "print(em / len(dataset.examples) * 100, recall / len(dataset.examples) * 100, hit / len(dataset.examples) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "united-venture",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "counts, bins, patch = plt.hist(hn_nums, bins=15, log=True)\n",
    "width = bins[1] - bins[0]\n",
    "for a, b in zip(bins, counts):\n",
    "    plt.text(a + width / 2, b + 0.05, '%.0f' % b if b > 0 else '', ha='center', va='bottom',fontsize=8)\n",
    "plt.show()\n",
    "print(f\"Max {max(hn_nums)}\")\n",
    "print(f\"Avg {sum(hn_nums) / len(hn_nums)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "internal-patrol",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# import json\n",
    "\n",
    "em = 0.\n",
    "recall = 0.\n",
    "hit = 0.\n",
    "hn_nums = []\n",
    "refined_examples = []\n",
    "split = 'dev'\n",
    "with open(f\"data/hotpot-step-{split}{'.strict' if is_strict else ''}.refined.1.jsonl\", 'w') as f1, open(f\"data/hotpot-step-{split}{'.strict' if is_strict else ''}.scored.1.jsonl\") as f2:\n",
    "    for line in f2:\n",
    "        scored_example = json.loads(line)\n",
    "        \n",
    "        sp_scores = scored_example['sp_scores']\n",
    "        hn_scores = scored_example['hn_scores']\n",
    "        hard_negs = scored_example['hard_negs']\n",
    "        assert len(hard_negs) == len(hn_scores)\n",
    "\n",
    "        min_sp_score = min(sp_scores)\n",
    "        sorted_hn_indices = sorted(list(range(len(hn_scores))), key=lambda idx: -hn_scores[idx])\n",
    "        refined_hn_ids, refined_hn_scores = [], []\n",
    "        for idx in sorted_hn_indices:\n",
    "            if len(refined_hn_ids) >= 30:\n",
    "                break\n",
    "            if len(refined_hn_ids) < 15 or hn_scores[idx] >= min(min_sp_score, 0.1):\n",
    "                refined_hn_ids.append(hard_negs[idx])\n",
    "                refined_hn_scores.append(hn_scores[idx])\n",
    "            else:\n",
    "                break\n",
    "        hn_nums.append(len(refined_hn_ids))\n",
    "        assert 15 <= len(refined_hn_ids) == len(refined_hn_scores) <= 30\n",
    "#         if min_sp_score < 0.001:\n",
    "#             print(sp_scores)\n",
    "#         if len(refined_hn_ids) > 20:\n",
    "#             print(sp_scores)\n",
    "#             print(len(refined_hn_scores), refined_hn_scores)\n",
    "\n",
    "        if min_sp_score > refined_hn_scores[0]:\n",
    "            em += 1.\n",
    "            recall += 1.\n",
    "            hit += 1.\n",
    "        elif max(sp_scores) > refined_hn_scores[1]:\n",
    "            em += 0.\n",
    "            recall += 0.5\n",
    "            hit += 1.\n",
    "        else:\n",
    "            em += 0.\n",
    "            recall += 0.\n",
    "            hit += 0.\n",
    "\n",
    "        refined_example = {\n",
    "            \"_id\": scored_example['_id'],\n",
    "            \"question\": scored_example['question'],\n",
    "            \"answer\": scored_example['answer'],\n",
    "            \"sp_facts\": scored_example['sp_facts'],\n",
    "            \"sp_ids\": scored_example['sp_ids'],\n",
    "            \"sp_scores\": sp_scores,\n",
    "            \"hard_negs\": refined_hn_ids,  # in- and out- neighbors of SPs, top ranked passages\n",
    "            \"hn_scores\": refined_hn_scores,\n",
    "            \"state2action\": scored_example['state2action']\n",
    "        }\n",
    "        refined_examples.append(refined_example)\n",
    "        f1.write(json.dumps(refined_example, ensure_ascii=False) + '\\n')\n",
    "\n",
    "print(sum(hn_nums) / len(hn_nums))\n",
    "print(em / len(refined_examples) * 100, recall / len(refined_examples) * 100, hit / len(refined_examples) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "satisfactory-circular",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "counts, bins, patch = plt.hist(hn_nums, bins=15, log=True)\n",
    "width = bins[1] - bins[0]\n",
    "for a, b in zip(bins, counts):\n",
    "    plt.text(a + width / 2, b + 0.05, '%.0f' % b if b > 0 else '', ha='center', va='bottom',fontsize=8)\n",
    "plt.show()\n",
    "print(f\"Max {max(hn_nums)}\")\n",
    "print(f\"Avg {sum(hn_nums) / len(hn_nums)}\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "looking-increase",
   "metadata": {},
   "source": [
    "electra-base-discriminator_DP0.5_HN2_M2_D2_adamW_SP0.5_B24_LR3.0e-05_WU0.1_E30_S42_02011536\n",
    "10.845644834571235\n",
    "67.06279540850777 82.03241053342336 97.00202565833897\n",
    "\n",
    "electra-base-discriminator_DP0.5_HN2_M2_D2_adamW_SP0.5_B32_LR3.0e-05_WU0.1_E30_S42_02031443\n",
    "10.505604321404457\n",
    "71.45172180958812 84.64550979068197 97.83929777177582\n",
    "\n",
    "rand-state-per-quest_electra-base-discriminator_DP0.5_HN2_M2_D2_adamW_SP0.5_B32_LR5.0e-05_WU0.1_E10_S42_01192233\n",
    "10.478865631330182\n",
    "70.033760972316 83.86225523295072 97.69074949358541\n",
    "\n",
    "rand-state-per-quest_electra-base-discriminator_DP0.5_HN2_M2_D2_adamW_SP0.5_B32_LR3.0e-05_WU0.1_E30_S42_01200749\n",
    "10.531532748143146\n",
    "71.08710330857528 84.34166103983794 97.59621877110061\n",
    "\n",
    "rand-state-per-quest_electra-base-discriminator_DP0.5_HN2_M2_D2_adamW_SP0.5_B32_LR5.0e-05_WU0.1_E30_S42_01201159\n",
    "10.50236326806212\n",
    "71.10060769750169 84.40243079000676 97.70425388251182\n",
    "\n",
    "rand-state-per-quest_electra-base-discriminator_DP0.5_HN2_M2_D2_adamW_SP0.5_B32_LR4.0e-05_WU0.1_E50_S42_01211727\n",
    "10.455638082376773\n",
    "70.18230925050642 83.88926401080352 97.59621877110061\n",
    "\n",
    "rand-state-per-quest_electra-base-discriminator_DP0.5_HN2_M2_D2_adamW_SP0.5_B32_LR3.0e-05_WU0.1_E30_S42_01271157_supervise-only-doing\n",
    "10.440648210668467\n",
    "71.34368669817691 84.55097906819717 97.75827143821742\n",
    "\n",
    "rand-state-per-quest_electra-base-discriminator_DP0.5_HN2_M2_D2_adamW_SP0.5_B32_LR3.0e-05_WU0.1_E30_S42_01290110_rank-memory-listmle\n",
    "10.429169480081026\n",
    "71.72180958811613 84.76704929101957 97.81228899392302\n",
    "\n",
    "rand-state-per-quest_electra-base-discriminator_DP0.5_HN2_M2_D2_adamW_SP0.5_B32_LR3.0e-05_WU0.1_E30_S42_02142159_para-loss-wo-weight-80\n",
    "10.45995948683322\n",
    "71.70830519918974 84.65226198514517 97.59621877110061\n",
    "\n",
    "rand-state-per-quest_electra-base-discriminator_DP0.5_HN2_M2_D2_adamW_SP0.5_B32_LR3.0e-05_WU0.1_E30_S42_02211559_para-loss-wo-weight-60\n",
    "10.585685347738014\n",
    "71.78933153274815 84.70627954085079 97.62322754895341\n",
    "\n",
    "rand-state-per-quest_electra-base-discriminator_DP0.5_HN2_M2_D2_adamW_SP0.5_B32_LR3.0e-05_WU0.1_E30_S42_02192257_para-loss-wo-weight-40\n",
    "10.4525320729237\n",
    "71.70830519918974 84.74679270762998 97.78528021607022\n",
    "\n",
    "rand-state-per-quest_electra-base-discriminator_DP0.5_HN2_M2_D2_adamW_SP0.5_B32_LR3.0e-05_WU0.1_E30_S42_02221740_para-loss-wo-weight-20\n",
    "10.50708980418636\n",
    "71.49223497636731 84.63875759621877 97.78528021607022\n",
    "\n",
    "rand-state-per-quest_electra-base-discriminator_DP0.5_HN2_M2_D2_adamW_SP0.5_B32_LR3.0e-05_WU0.1_E30_S42_03022101_para-loss-wo-weight-20\n",
    "10.400810263335584\n",
    "73.20729237002026 85.60432140445646 98.00135043889264\n",
    "\n",
    "rand-state-per-quest_electra-base-discriminator_DP0.5_HN2_M2_D2_adamW_SP0.5_B32_LR2.0e-05_WU0.1_E30_S42_03040341_para-loss-wo-weight-20\n",
    "73.39635381498987 85.83389601620527 98.27143821742067\n",
    "\n",
    "rand-state-per-quest_electra-base-discriminator_DP0.5_HN2_M3_D2_adamW_SP0.5_B32_LR2.0e-05_WU0.1_E30_S42_03050950_para-loss-wo-weight-20\n",
    "10.35624577987846\n",
    "73.69345037137069 85.94868332207967 98.20391627278866\n",
    "\n",
    "rand-state-per-quest_electra-base-discriminator_DP0.5_HN2_M2_D2_adamW_SP0.5_B32_LR2.0e-05_WU0.1_E30_S42_03062128_na-3\n",
    "10.4559081701553\n",
    "74.20661715057393 86.2795408507765 98.35246455097906\n",
    "\n",
    "rand-state-per-quest_electra-base-discriminator_DP0.5_HN2_M3_D2_adamW_SP0.5_B32_LR2.0e-05_WU0.1_E30_S42_03080350_na-3\n",
    "10.428224172856178\n",
    "73.36934503713707 85.86090479405807 98.35246455097906\n",
    "\n",
    "rand-state-per-quest_electra-base-discriminator_DP0.5_HN2_M3_D2_adamW_SP0.5_B32_LR2.0e-05_WU0.1_E30_S42_03091656_td4 (interrupted)\n",
    "10.452667116812965\n",
    "73.57191087103308 86.00270087778527 98.43349088453748\n",
    "\n",
    "rand-state-per-quest_electra-base-discriminator_DP0.5_HN2_M2_D2_adamW_SP0.5_B32_LR2.0e-05_WU0.1_E30_S42_03101915_ignore (interrupted)\n",
    "10.50438892640108\n",
    "72.5725860904794 85.54355165428764 98.51451721809588\n",
    "\n",
    "rand-state-per-quest_electra-base-discriminator_DP0.5_HN2_M3_D3_adamW_SP0.5_B32_LR2.0e-05_WU0.1_E30_S42_03111009_ignore-al (interrupted)\n",
    "10.4491559756921\n",
    "72.95070898041864 85.63133018230926 98.31195138419987\n",
    "\n",
    "rand-state-per-quest_electra-base-discriminator_DP0.5_HN2_M3_D3_adamW_SP0.5_B32_LR2.0e-05_WU0.1_E30_S42_03131057_adjust-l0\n",
    "10.433896016205267\n",
    "73.20729237002026 85.77312626603646 98.33896016205267\n",
    "10.433220796758947\n",
    "73.88251181634031 86.06347062795409 98.24442943956785\n",
    "\n",
    "rand-state-per-quest_electra-base-discriminator_DP0.5_HN2_M2_D2_adamW_SP0.5_B32_LR2.0e-05_WU0.1_E30_S42_03141928_al-ia\n",
    "10.343011478730588\n",
    "73.53139770425389 85.92842673869008 98.32545577312627\n",
    "10.412288993923026\n",
    "74.35516542876435 86.2795408507765 98.20391627278866\n",
    "\n",
    "rand-state-per-quest_electra-base-discriminator_DP0.5_HN2_M2_D2_adamW_SP0.5_B32_LR2.0e-05_WU0.1_E30_S42_03152213_ial\n",
    "10.40472653612424\n",
    "73.88251181634031 86.07697501688048 98.27143821742067\n",
    "10.395003376097232\n",
    "74.11208642808913 86.2187711006077 98.32545577312627\n",
    "\n",
    "rand-state-per-quest_electra-base-discriminator_DP0.5_HN2_M2_D2_adamW_SP0.5_B32_LR2.0e-05_WU0.1_E30_S42_03192339_td3-ila.5\n",
    "10.412018906144496\n",
    "73.7879810938555 86.02970965563809 98.27143821742067\n",
    "10.395408507765024\n",
    "74.57123565158676 86.46185010128292 98.35246455097906\n",
    "\n",
    "rand-state-per-quest_electra-base-discriminator_DP0.5_HN2_M2_D2_adamW_SP0.5_B32_LR2.0e-05_WU0.1_E30_S42_03270146_td3-ila.4\n",
    "15.231870357866306\n",
    "73.89601620526672 86.09047940580689 98.28494260634706\n",
    "15.231465226198514\n",
    "74.62525320729237 86.42808912896692 98.23092505064146\n",
    "\n",
    "rand-state-per-quest_electra-base-discriminator_DP0.5_HN2_M2_D2_adamW_SP0.5_B32_LR2.0e-05_WU0.1_E30_S42_03240200_td3\n",
    "15.232140445644834\n",
    "73.7879810938555 86.09723160027009 98.40648210668466\n",
    "15.232275489534098\n",
    "74.19311276164754 86.2862930452397 98.37947332883186\n",
    "\n",
    "td5-exp1-ila.4_electra-large-discriminator_DP0.5_HN2_M2_D2_adamW_SP0.5_B24_LR6.0e-06_WU0.1_E30_S42_04250100_pld-sb0-wo*\n",
    "15.336529372045915\n",
    "77.86630654962863 88.32545577312627 98.7846049966239\n",
    "\n",
    "td5-exp1-ila.4_electra-large-discriminator_DP0.5_HN2_M2_D2_adamW_SP0.5_B32_LR2.0e-05_WU0.1_E30_S42_04270247_pld-sb0-wo*-cmd10\n",
    "15.46495611073599\n",
    "77.90681971640784 88.29844699527347 98.69007427413909\n",
    "\n",
    "td5-exp1-ila.4_electra-large-discriminator_DP0.5_HN2_M2_D2_adamW_SP0.5_B32_LR1.0e-05_WU0.1_E30_S42_04290856_pld-sb0-wo*\n",
    "15.393517893315327\n",
    "77.74476704929101 88.29844699527347 98.85212694125592"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
