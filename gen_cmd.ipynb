{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=3,2,1,0\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%env CUDA_VISIBLE_DEVICES=3,2,1,0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def set_seed(seed):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    \n",
    "    random.seed(seed)\n",
    "    \n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed) # if you are using multi-GPU.\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "def set_global_logging_level(level=logging.ERROR, prefixes=(\"\",)):\n",
    "    \"\"\"\n",
    "    Override logging levels of different modules based on their name as a prefix.\n",
    "    It needs to be invoked after the modules have been loaded so that their loggers have been initialized.\n",
    "\n",
    "    Args:\n",
    "        level: desired level. Optional. Default is logging.ERROR\n",
    "        prefixes: list of one or more str prefixes to match (e.g. [\"transformers\", \"torch\"]). Optional.\n",
    "            Default is `[\"\"]` to match all active loggers.\n",
    "            The match is a case-sensitive `module_name.startswith(prefix)`\n",
    "    \"\"\"\n",
    "    prefix_re = re.compile(fr'^(?:{\"|\".join(prefixes)})')\n",
    "    for name in logging.root.manager.loggerDict:\n",
    "        if re.match(prefix_re, name):\n",
    "            logging.getLogger(name).setLevel(level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(0)\n",
    "# set_global_logging_level(logging.WARNING, [\"elasticsearch\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true"
   },
   "source": [
    "## Load examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7405\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "samples = []\n",
    "with open(\"data/hotpot-dev.tsv\") as f:\n",
    "    for line in f:\n",
    "        q_id, question, answer, sp_facts = line.strip().split('\\t')\n",
    "        sp_facts = json.loads(sp_facts)\n",
    "        samples.append((q_id, (question, answer, sp_facts)))\n",
    "print(len(samples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true"
   },
   "source": [
    "## Load sparse retriever and query generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from retriever import SparseRetriever\n",
    "\n",
    "sparse_retriever = SparseRetriever('enwiki-20171001-paragraph-5', ['10.60.0.59:9200'], timeout=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:WARN: Duplicate embedding found for ����������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������\n",
      "WARNING:root:WARN: Duplicate embedding found for Kṛṣṇa\n",
      "WARNING:root:WARN: Duplicate embedding found for Decisión\n",
      "WARNING:root:WARN: Duplicate embedding found for decisión\n",
      "WARNING:root:WARN: Duplicate embedding found for Viṣṇu\n",
      "WARNING:root:WARN: Duplicate embedding found for Justiça\n",
      "WARNING:root:WARN: Duplicate embedding found for Acórdão\n",
      "WARNING:root:WARN: Duplicate embedding found for ̲̅̅\n",
      "WARNING:root:WARN: Duplicate embedding found for Câmara\n",
      "WARNING:root:WARN: Duplicate embedding found for brāhmaṇa\n",
      "WARNING:root:WARN: Duplicate embedding found for Extensión\n",
      "WARNING:root:WARN: Duplicate embedding found for Cível\n",
      "WARNING:root:WARN: Duplicate embedding found for brāhmaṇas\n",
      "WARNING:root:WARN: Duplicate embedding found for Vṛndāvana\n",
      "WARNING:root:WARN: Duplicate embedding found for Cañon\n",
      "WARNING:root:WARN: Duplicate embedding found for Arrêté\n",
      "WARNING:root:WARN: Duplicate embedding found for kΩ\n",
      "WARNING:root:WARN: Duplicate embedding found for Córdova\n",
      "WARNING:root:WARN: Duplicate embedding found for justiça\n",
      "WARNING:root:WARN: Duplicate embedding found for acórdão\n",
      "WARNING:root:WARN: Duplicate embedding found for Ṭhākura\n",
      "WARNING:root:WARN: Duplicate embedding found for États\n",
      "WARNING:root:WARN: Duplicate embedding found for Nārāyaṇa\n",
      "WARNING:root:WARN: Duplicate embedding found for Resolución\n",
      "WARNING:root:WARN: Duplicate embedding found for extensión\n",
      "WARNING:root:WARN: Duplicate embedding found for ʹ\n",
      "WARNING:root:WARN: Duplicate embedding found for Vaiṣṇava\n",
      "WARNING:root:WARN: Duplicate embedding found for của\n",
      "WARNING:root:WARN: Duplicate embedding found for câmara\n",
      "WARNING:root:WARN: Duplicate embedding found for Região\n",
      "WARNING:root:WARN: Duplicate embedding found for siècle\n",
      "WARNING:root:WARN: Duplicate embedding found for Parīkṣit\n",
      "WARNING:root:WARN: Duplicate embedding found for Décima\n",
      "WARNING:root:WARN: Duplicate embedding found for mΩ\n",
      "WARNING:root:WARN: Duplicate embedding found for Protección\n",
      "WARNING:root:WARN: Duplicate embedding found for cível\n",
      "WARNING:root:WARN: Duplicate embedding found for Miró\n",
      "WARNING:root:WARN: Duplicate embedding found for MΩ\n",
      "WARNING:root:WARN: Duplicate embedding found for arrêté\n",
      "WARNING:root:WARN: Duplicate embedding found for Tháng\n",
      "WARNING:root:WARN: Duplicate embedding found for ����������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������\n",
      "WARNING:root:WARN: Duplicate embedding found for Decisión\n",
      "WARNING:root:WARN: Duplicate embedding found for decisión\n",
      "WARNING:root:WARN: Duplicate embedding found for Acórdão\n",
      "WARNING:root:WARN: Duplicate embedding found for ̲̅̅\n",
      "WARNING:root:WARN: Duplicate embedding found for brāhmaṇa\n",
      "WARNING:root:WARN: Duplicate embedding found for Extensión\n",
      "WARNING:root:WARN: Duplicate embedding found for Cível\n",
      "WARNING:root:WARN: Duplicate embedding found for brāhmaṇas\n",
      "WARNING:root:WARN: Duplicate embedding found for Vṛndāvana\n",
      "WARNING:root:WARN: Duplicate embedding found for kΩ\n",
      "WARNING:root:WARN: Duplicate embedding found for justiça\n",
      "WARNING:root:WARN: Duplicate embedding found for acórdão\n",
      "WARNING:root:WARN: Duplicate embedding found for Ṭhākura\n",
      "WARNING:root:WARN: Duplicate embedding found for Resolución\n",
      "WARNING:root:WARN: Duplicate embedding found for extensión\n",
      "WARNING:root:WARN: Duplicate embedding found for ʹ\n",
      "WARNING:root:WARN: Duplicate embedding found for Parīkṣit\n",
      "WARNING:root:WARN: Duplicate embedding found for mΩ\n",
      "WARNING:root:WARN: Duplicate embedding found for cível\n",
      "WARNING:root:WARN: Duplicate embedding found for MΩ\n",
      "WARNING:root:WARN: Duplicate embedding found for arrêté\n",
      "WARNING:root:WARN: Duplicate embedding found for Tháng\n"
     ]
    }
   ],
   "source": [
    "# %env CLASSPATH=corenlp/*\n",
    "from drqa.reader import Predictor\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# import os\n",
    "# os.environ['CLASSPATH'] = 'corenlp/*'\n",
    "\n",
    "qg1 = Predictor(model='ckpts/golden-retriever/hop1.mdl', tokenizer=None, embedding_file='data/glove.840B.300d.txt', num_workers=-1)\n",
    "qg1.cuda()\n",
    "# qg1.model.network.to(torch.device('cuda:0'))\n",
    "qg2 = Predictor(model='ckpts/golden-retriever/hop2.mdl', tokenizer=None, embedding_file='data/glove.840B.300d.txt', num_workers=-1)\n",
    "qg2.cuda()\n",
    "# qg2.model.network.to(torch.device('cuda:0'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true"
   },
   "source": [
    "## Load dense retriever and query encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "faiss.omp_set_num_threads(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import Namespace\n",
    "\n",
    "args = Namespace(**{\n",
    "    \"model_name\": \"roberta-base\",\n",
    "    \"model_path\": \"ckpts/mdr/q_encoder.pt\",\n",
    "    \"index_prefix_path\": \"data/index/mdr/hotpot-paragraph-q-strict.hnsw\",\n",
    "    \"index_buffer_size\": 50000,\n",
    "    \"max_q_len\": 70,\n",
    "    \"max_q_sp_len\": 350\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaCtxEncoder(\n",
       "  (encoder): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (project): Sequential(\n",
       "    (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoConfig, AutoTokenizer\n",
    "from mdr.retrieval.models.retriever import RobertaCtxEncoder\n",
    "from utils.model_utils import load_state\n",
    "\n",
    "bert_config = AutoConfig.from_pretrained(args.model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(args.model_name)\n",
    "query_encoder = RobertaCtxEncoder(bert_config, args)\n",
    "query_encoder = load_state(query_encoder, args.model_path, exact=False)\n",
    "device = torch.device('cuda:1')\n",
    "query_encoder.to(device)\n",
    "# if torch.cuda.device_count() > 1:\n",
    "#     query_encoder = torch.nn.DataParallel(query_encoder)\n",
    "query_encoder.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dense_indexers import DenseHNSWFlatIndexer, DenseFlatIndexer\n",
    "\n",
    "vector_size = bert_config.hidden_size\n",
    "dense_indexer = DenseHNSWFlatIndexer(vector_size, args.index_buffer_size)\n",
    "dense_indexer.deserialize_from(args.index_prefix_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from retriever import DenseRetriever\n",
    "\n",
    "dense_retriever = DenseRetriever(dense_indexer, query_encoder, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true"
   },
   "source": [
    "## Load corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5232080\n",
      "5232080\n"
     ]
    }
   ],
   "source": [
    "from utils.data_utils import load_corpus\n",
    "\n",
    "corpus, title2id = load_corpus('data/corpus/hotpot-paragraph-5.tsv', for_hotpot=True, require_hyperlinks=True)\n",
    "print(len(corpus))\n",
    "print(len(title2id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate oracle commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [sample[1][0] for sample in samples]  # (N,)\n",
    "questions = [q[:-1] if q.endswith('?') else q for q in questions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_global_logging_level(logging.WARNING, [\"elasticsearch\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import redis\n",
    "\n",
    "query_redis = redis.Redis(host='10.60.1.79', port=6379, db=2, password='redis4zyc', decode_responses=True)\n",
    "bm25_redis = redis.Redis(host='10.60.1.79', port=6379, db=3, password='redis4zyc', decode_responses=True)  # 0\n",
    "mdr_redis = redis.Redis(host='10.60.1.79', port=6379, db=4, password='redis4zyc', decode_responses=True)  # 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 707/707 [11:41<00:00,  1.01it/s]\n"
     ]
    }
   ],
   "source": [
    "hits_list1 = dense_retriever.msearch(questions, max(RET_SIZE, 1000), args.max_q_len, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "for question, hits_list in zip(questions, hits_list1):\n",
    "    if not mdr_redis.exists(question) or (mdr_redis.llen(question) < RET_SIZE and mdr_redis.lindex(question, -1) != 'EOL'):\n",
    "        hits = hits_list[0]\n",
    "        mdr_redis.delete(question)\n",
    "        if len(hits) < RET_SIZE:\n",
    "            mdr_redis.rpush(question, *(hits + ['EOL']))\n",
    "        else:\n",
    "            mdr_redis.rpush(question, *hits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e729e12871d4f09a8f26fb83b1e5cda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=7405.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable recall SP2 through the first 100 retrieval results: 5a7d54165542995f4f402256\n",
      "Unable recall SP2 through the first 100 retrieval results: 5a77152355429966f1a36c2e\n",
      "Unable recall SP2 through the first 100 retrieval results: 5ae7ba7a5542993210983f12\n",
      "Unable recall SP1 through the first 100 retrieval results: 5ae738f75542991bbc9761c4\n",
      "Unable recall SP2 through the first 100 retrieval results: 5a713a5a5542994082a3e6a9\n",
      "Unable recall SP2 through the first 100 retrieval results: 5ab7f0015542992aa3b8c88b\n",
      "Unable recall SP2 through the first 100 retrieval results: 5ac547525542993e66e822a3\n",
      "Unable recall SP2 through the first 100 retrieval results: 5ab7f97a5542991d322237ef\n",
      "Unable recall SP2 through the first 100 retrieval results: 5a77cb5e55429967ab1052a7\n",
      "Unable recall SP2 through the first 100 retrieval results: 5a7f6eab5542992097ad2f66\n",
      "Unable recall SP2 through the first 100 retrieval results: 5a8f69b55542997ba9cb324f\n",
      "Unable recall SP1 through the first 100 retrieval results: 5ae1f596554299234fd04372\n",
      "Unable recall SP2 through the first 100 retrieval results: 5ae09ce855429924de1b7113\n",
      "Unable recall SP2 through the first 100 retrieval results: 5a7319e755429901807daf86\n",
      "Unable recall SP2 through the first 100 retrieval results: 5a84f7255542991dd0999e33\n",
      "Unable recall SP2 through the first 100 retrieval results: 5ab5ec0a5542997d4ad1f250\n",
      "Unable recall SP1 through the first 100 retrieval results: 5ab438395542990594ba9bb9\n",
      "Unable recall SP2 through the first 100 retrieval results: 5a8752955542994775f607d1\n",
      "Unable recall SP2 through the first 100 retrieval results: 5a7766b15542993569682d7e\n",
      "Unable recall SP1 through the first 100 retrieval results: 5ae1b2b9554299422ee99684\n",
      "Unable recall SP2 through the first 100 retrieval results: 5ae18d615542997283cd2229\n",
      "Unable recall SP2 through the first 100 retrieval results: 5a77d65055429949eeb29f7b\n",
      "Unable recall SP2 through the first 100 retrieval results: 5a901f735542990a98493591\n",
      "Unable recall SP1 through the first 100 retrieval results: 5ac29cf8554299218029dac2\n",
      "Unable recall SP1 through the first 100 retrieval results: 5ae70ed7554299572ea546a1\n",
      "Unable recall SP2 through the first 100 retrieval results: 5a7f62405542992e7d278cf0\n",
      "Unable recall SP2 through the first 100 retrieval results: 5a8347d65542996488c2e3f6\n",
      "Unable recall SP2 through the first 100 retrieval results: 5ab38cdd5542992ade7c6de2\n",
      "Unable recall SP1 through the first 100 retrieval results: 5abe535055429976d4830aea\n",
      "Unable recall SP2 through the first 100 retrieval results: 5a8df1a65542995085b3735f\n",
      "Unable recall SP1 through the first 100 retrieval results: 5ab53ad6554299488d4d9917\n",
      "Unable recall SP1 through the first 100 retrieval results: 5ab27389554299722f9b4d2f\n",
      "Unable recall SP1 through the first 100 retrieval results: 5abf8ae85542990832d3a14b\n",
      "Unable recall SP2 through the first 100 retrieval results: 5a775f615542993735360250\n",
      "Unable recall SP1 through the first 100 retrieval results: 5a868ca055429960ec39b6be\n",
      "Unable recall SP2 through the first 100 retrieval results: 5ab7ee895542995dae37e9f6\n",
      "Unable recall SP2 through the first 100 retrieval results: 5aba902455429901930fa834\n",
      "Unable recall SP2 through the first 100 retrieval results: 5a83a31c554299123d8c2179\n",
      "Unable recall SP1 through the first 100 retrieval results: 5ae4ea2a5542993aec5ec0ee\n",
      "Unable recall SP1 through the first 100 retrieval results: 5a8e296f554299068b959e71\n",
      "Unable recall SP2 through the first 100 retrieval results: 5ac4f2e755429924173fb503\n",
      "Unable recall SP2 through the first 100 retrieval results: 5a776fc15542997042120a3a\n",
      "Unable recall SP2 through the first 100 retrieval results: 5a84a8ce5542997175ce1f1c\n",
      "Unable recall SP2 through the first 100 retrieval results: 5a77174f55429966f1a36c4c\n",
      "Unable recall SP2 through the first 100 retrieval results: 5a75d8a3554299109176e5a6\n",
      "Unable recall SP2 through the first 100 retrieval results: 5ab762fb55429928e1fe3857\n",
      "Unable recall SP2 through the first 100 retrieval results: 5a739d8c55429905862fe073\n",
      "Unable recall SP2 through the first 100 retrieval results: 5a739b1955429978a71e9044\n",
      "Unable recall SP2 through the first 100 retrieval results: 5abb23035542992ccd8e7f22\n",
      "Unable recall SP2 through the first 100 retrieval results: 5a8d1f015542994ba4e3dc08\n",
      "Unable recall SP2 through the first 100 retrieval results: 5a78caa955429970f5fffd83\n",
      "Unable recall SP2 through the first 100 retrieval results: 5a90629855429916514e749e\n",
      "Unable recall SP2 through the first 100 retrieval results: 5adf39765542993a75d26435\n",
      "Unable recall SP2 through the first 100 retrieval results: 5abd05e655429965836004f1\n",
      "Unable recall SP2 through the first 100 retrieval results: 5ae17d6855429901ffe4aea7\n",
      "Unable recall SP1 through the first 100 retrieval results: 5a7140585542994082a3e6fa\n",
      "Unable recall SP2 through the first 100 retrieval results: 5ae0156455429942ec259c15\n",
      "Unable recall SP2 through the first 100 retrieval results: 5ab262a4554299340b5254ac\n",
      "Unable recall SP2 through the first 100 retrieval results: 5a81d81e554299676cceb0f6\n",
      "Unable recall SP2 through the first 100 retrieval results: 5ae375955542990afbd1e15d\n",
      "Unable recall SP2 through the first 100 retrieval results: 5adc9d145542994d58a2f67d\n",
      "Unable recall SP1 through the first 100 retrieval results: 5a81a4615542995ce29dcc1e\n",
      "Unable recall SP2 through the first 100 retrieval results: 5a75404a55429916b01642be\n",
      "Unable recall SP1 through the first 100 retrieval results: 5abf8e135542990832d3a14f\n",
      "Unable recall SP1 through the first 100 retrieval results: 5adfd0d455429942ec259b4d\n",
      "Unable recall SP2 through the first 100 retrieval results: 5ae5e762554299546bf82faf\n",
      "Unable recall SP2 through the first 100 retrieval results: 5a8468c95542990548d0b2b1\n",
      "Unable recall SP2 through the first 100 retrieval results: 5a81a4335542990a1d231e38\n",
      "Unable recall SP2 through the first 100 retrieval results: 5ac009bf5542997d642959a7\n",
      "Unable recall SP2 through the first 100 retrieval results: 5adbe75455429944faac23af\n",
      "Unable recall SP2 through the first 100 retrieval results: 5a85f98e5542996432c57152\n",
      "Unable recall SP2 through the first 100 retrieval results: 5a7344e95542991f9a20c6ce\n",
      "Unable recall SP2 through the first 100 retrieval results: 5abd648155429933744ab7ac\n",
      "Unable recall SP1 through the first 100 retrieval results: 5abacac45542996cc5e49e94\n",
      "Unable recall SP2 through the first 100 retrieval results: 5ab1e3bb554299340b52541a\n",
      "Unable recall SP2 through the first 100 retrieval results: 5adcc90c5542990d50227d1b\n",
      "Unable recall SP2 through the first 100 retrieval results: 5ab3eb1955429969a97a81f6\n",
      "Unable recall SP2 through the first 100 retrieval results: 5ae600325542992663a4f237\n",
      "Unable recall SP2 through the first 100 retrieval results: 5a869e845542991e7718166f\n",
      "Unable recall SP1 through the first 100 retrieval results: 5a904f6355429916514e746e\n",
      "Unable recall SP1 through the first 100 retrieval results: 5a7630105542992d0ec0605a\n",
      "Unable recall SP2 through the first 100 retrieval results: 5a8f186055429918e830d186\n",
      "Unable recall SP2 through the first 100 retrieval results: 5ae4f2595542990ba0bbb1a8\n",
      "Unable recall SP1 through the first 100 retrieval results: 5a8066d15542992097ad2fe8\n",
      "Unable recall SP2 through the first 100 retrieval results: 5ade630e55429975fa854eb7\n",
      "Unable recall SP2 through the first 100 retrieval results: 5ae4cf975542990ba0bbb151\n",
      "Unable recall SP1 through the first 100 retrieval results: 5a86681c5542991e77181644\n",
      "Unable recall SP2 through the first 100 retrieval results: 5abbc3a955429931dba144f9\n",
      "Unable recall SP2 through the first 100 retrieval results: 5ae206c45542994d89d5b311\n",
      "Unable recall SP2 through the first 100 retrieval results: 5ab259b25542993be8fa98de\n",
      "Unable recall SP2 through the first 100 retrieval results: 5a72f3a85542992359bc31e5\n",
      "Unable recall SP2 through the first 100 retrieval results: 5a750d315542996c70cfae84\n",
      "Unable recall SP1 through the first 100 retrieval results: 5a8bb90f5542996e8ac88a02\n",
      "Unable recall SP2 through the first 100 retrieval results: 5ae7739c5542997b22f6a775\n",
      "Unable recall SP2 through the first 100 retrieval results: 5ac04a265542997d642959f1\n",
      "Unable recall SP2 through the first 100 retrieval results: 5a78a862554299148911f8fe\n",
      "Unable recall SP2 through the first 100 retrieval results: 5abd0097554299700f9d7956\n",
      "Unable recall SP2 through the first 100 retrieval results: 5ac2bcf55542990b17b1546e\n",
      "Unable recall SP2 through the first 100 retrieval results: 5ab298fb554299449642c922\n",
      "Unable recall SP2 through the first 100 retrieval results: 5a7f669a5542994857a76729\n",
      "Unable recall SP1 through the first 100 retrieval results: 5a81d51a55429903bc27b9d2\n",
      "Unable recall SP1 through the first 100 retrieval results: 5a8a12ae5542992d82986e92\n",
      "Unable recall SP2 through the first 100 retrieval results: 5aba75e655429955dce3ee3c\n",
      "Unable recall SP2 through the first 100 retrieval results: 5a8b7cb95542995d1e6f13bb\n",
      "Unable recall SP1 through the first 100 retrieval results: 5a7509175542993748c897a3\n",
      "Unable recall SP2 through the first 100 retrieval results: 5a824e0b554299676cceb254\n",
      "Unable recall SP2 through the first 100 retrieval results: 5a7354e35542994cef4bc55b\n",
      "Unable recall SP1 through the first 100 retrieval results: 5ab2118055429970612095b8\n",
      "Unable recall SP2 through the first 100 retrieval results: 5a7e32905542991319bc943b\n",
      "Unable recall SP2 through the first 100 retrieval results: 5a8b86645542997f31a41d62\n",
      "Unable recall SP2 through the first 100 retrieval results: 5a74be7a55429929fddd84e4\n",
      "Unable recall SP2 through the first 100 retrieval results: 5ae5086d55429908b63264eb\n",
      "Unable recall SP2 through the first 100 retrieval results: 5a80b9df5542992bc0c4a7ec\n",
      "Unable recall SP2 through the first 100 retrieval results: 5ac49a1c5542996feb3fe905\n",
      "Unable recall SP2 through the first 100 retrieval results: 5a83cce95542996488c2e4d6\n",
      "Unable recall SP2 through the first 100 retrieval results: 5ab7c24e5542995dae37e998\n",
      "Unable recall SP2 through the first 100 retrieval results: 5ab3b42c5542992ade7c6e4f\n",
      "Unable recall SP2 through the first 100 retrieval results: 5ae7a6da5542994a481bbdb9\n",
      "Unable recall SP2 through the first 100 retrieval results: 5a89bcc85542992e4fca83a7\n",
      "Unable recall SP2 through the first 100 retrieval results: 5ac273455542992f1f2b38d4\n",
      "Unable recall SP1 through the first 100 retrieval results: 5a721a7655429971e9dc9271\n",
      "Unable recall SP2 through the first 100 retrieval results: 5ac2570a5542992f1f2b3861\n",
      "Unable recall SP2 through the first 100 retrieval results: 5a8b20b85542996c9b8d5fb5\n",
      "Unable recall SP2 through the first 100 retrieval results: 5add5f395542990dbb2f7e50\n",
      "Unable recall SP2 through the first 100 retrieval results: 5a825b0e55429954d2e2eb0c\n",
      "Unable recall SP1 through the first 100 retrieval results: 5ab3c53955429969a97a81b9\n",
      "Unable recall SP2 through the first 100 retrieval results: 5abdce1b5542993062266cfe\n",
      "Unable recall SP2 through the first 100 retrieval results: 5a78ce5d55429974737f78ac\n",
      "Unable recall SP2 through the first 100 retrieval results: 5ac175635542994ab5c67d4b\n",
      "Unable recall SP2 through the first 100 retrieval results: 5a8efb5a55429918e830d172\n",
      "Unable recall SP2 through the first 100 retrieval results: 5ab36c3f55429969a97a8146\n",
      "Unable recall SP2 through the first 100 retrieval results: 5a7619765542992db9473728\n",
      "Unable recall SP2 through the first 100 retrieval results: 5ab27f7b554299722f9b4d4f\n",
      "Unable recall SP2 through the first 100 retrieval results: 5a7353b35542994cef4bc54f\n",
      "Unable recall SP2 through the first 100 retrieval results: 5a7af08655429931da12c989\n",
      "Unable recall SP1 through the first 100 retrieval results: 5a84bda45542992a431d1a96\n",
      "Unable recall SP2 through the first 100 retrieval results: 5a90b1635542990a984936a9\n",
      "Unable recall SP2 through the first 100 retrieval results: 5a79186f55429907847277af\n",
      "Unable recall SP2 through the first 100 retrieval results: 5a75fa8c55429976ec32bcda\n",
      "Unable recall SP2 through the first 100 retrieval results: 5a7115475542994082a3e56d\n",
      "Unable recall SP2 through the first 100 retrieval results: 5ae7620f5542997ec2727627\n",
      "Unable recall SP2 through the first 100 retrieval results: 5ab2a292554299194fa93496\n",
      "Unable recall SP2 through the first 100 retrieval results: 5a7bacf2554299294a54aa8d\n",
      "Unable recall SP2 through the first 100 retrieval results: 5a78d38455429970f5fffd94\n",
      "Unable recall SP2 through the first 100 retrieval results: 5a7b78c35542997c3ec971a9\n",
      "Unable recall SP2 through the first 100 retrieval results: 5ae269955542992decbdccf3\n",
      "Unable recall SP2 through the first 100 retrieval results: 5a810d5255429926c1cdacd8\n",
      "Unable recall SP2 through the first 100 retrieval results: 5ab43b9d5542990594ba9bc3\n",
      "Unable recall SP2 through the first 100 retrieval results: 5ac24d725542996366519966\n",
      "Unable recall SP2 through the first 100 retrieval results: 5a81736255429903bc27b96e\n",
      "Unable recall SP2 through the first 100 retrieval results: 5a8a573355429970aeb7029a\n",
      "Unable recall SP1 through the first 100 retrieval results: 5a77857155429949eeb29ebf\n",
      "Unable recall SP2 through the first 100 retrieval results: 5a802b595542995d8a8ddf51\n",
      "Unable recall SP2 through the first 100 retrieval results: 5ab85d6c55429919ba4e22cb\n",
      "Unable recall SP2 through the first 100 retrieval results: 5a7717635542994aec3b71e3\n",
      "Unable recall SP2 through the first 100 retrieval results: 5adc995d5542994ed6169ba8\n",
      "Unable recall SP2 through the first 100 retrieval results: 5a7fa2ad5542994857a76792\n",
      "Unable recall SP1 through the first 100 retrieval results: 5a81778355429926c1cdad2e\n",
      "Unable recall SP2 through the first 100 retrieval results: 5a8d227a554299585d9e37b1\n",
      "Unable recall SP2 through the first 100 retrieval results: 5ab5d4eb5542992aa134a3aa\n",
      "Unable recall SP2 through the first 100 retrieval results: 5a7268235542992359bc3081\n",
      "Unable recall SP2 through the first 100 retrieval results: 5ae395d85542992f92d82313\n",
      "Unable recall SP2 through the first 100 retrieval results: 5abbc4f955429931dba144ff\n",
      "Unable recall SP2 through the first 100 retrieval results: 5a84b2995542994c784dda11\n",
      "Unable recall SP2 through the first 100 retrieval results: 5abd14c455429924427fceec\n",
      "Unable recall SP2 through the first 100 retrieval results: 5ab29b07554299194fa93440\n",
      "Unable recall SP2 through the first 100 retrieval results: 5a772c395542993735360207\n",
      "Unable recall SP1 through the first 100 retrieval results: 5a721bbc55429971e9dc9279\n",
      "Unable recall SP1 through the first 100 retrieval results: 5ae4885e55429970de88d99d\n",
      "Unable recall SP2 through the first 100 retrieval results: 5a7d2b2b5542995ed0d1661b\n",
      "Unable recall SP1 through the first 100 retrieval results: 5a800ddd5542992097ad2fd0\n",
      "Unable recall SP1 through the first 100 retrieval results: 5ab7ece25542995dae37e9f3\n",
      "Unable recall SP2 through the first 100 retrieval results: 5a8eed625542995085b374b9\n",
      "Unable recall SP1 through the first 100 retrieval results: 5a83ef745542996488c2e4f8\n",
      "Unable recall SP1 through the first 100 retrieval results: 5a860d09554299211dda2a53\n",
      "Unable recall SP2 through the first 100 retrieval results: 5a9092cc55429916514e74fd\n",
      "Unable recall SP1 through the first 100 retrieval results: 5ab568af554299494045efaf\n",
      "Unable recall SP1 through the first 100 retrieval results: 5ab7fd6b5542990e739ec7b5\n",
      "Unable recall SP2 through the first 100 retrieval results: 5a729cc25542991f9a20c532\n",
      "Unable recall SP2 through the first 100 retrieval results: 5a87bd4e5542996432c57279\n",
      "Unable recall SP2 through the first 100 retrieval results: 5ae622495542995703ce8b20\n",
      "Unable recall SP2 through the first 100 retrieval results: 5a7481d755429974ef308c12\n",
      "Unable recall SP2 through the first 100 retrieval results: 5a82ffef55429954d2e2ebf2\n",
      "Unable recall SP1 through the first 100 retrieval results: 5a8af1e255429950cd6afc28\n",
      "Unable recall SP2 through the first 100 retrieval results: 5ab1e75f554299340b525422\n",
      "Unable recall SP2 through the first 100 retrieval results: 5a74994a55429974ef308c2e\n",
      "Unable recall SP2 through the first 100 retrieval results: 5adf29f05542993344016c09\n",
      "Unable recall SP2 through the first 100 retrieval results: 5a710a1e5542994082a3e4fd\n",
      "Unable recall SP2 through the first 100 retrieval results: 5a74ae6a55429916b01641c9\n",
      "Unable recall SP2 through the first 100 retrieval results: 5a7518cb55429916b0164259\n",
      "Unable recall SP1 through the first 100 retrieval results: 5ac0b8395542996f0d89cc21\n",
      "Unable recall SP2 through the first 100 retrieval results: 5ac23f5255429951e9e684d8\n",
      "Unable recall SP2 through the first 100 retrieval results: 5abe9c1a5542993f32c2a183\n",
      "Unable recall SP2 through the first 100 retrieval results: 5ae724ec5542995703ce8bd8\n",
      "Unable recall SP1 through the first 100 retrieval results: 5a74b4dc55429979e2882a00\n",
      "Unable recall SP1 through the first 100 retrieval results: 5a809e9f5542996402f6a5b1\n",
      "Unable recall SP2 through the first 100 retrieval results: 5a8fab8c5542995b4424208a\n",
      "Unable recall SP1 through the first 100 retrieval results: 5a74f3f55542993748c8974b\n",
      "Unable recall SP1 through the first 100 retrieval results: 5ae39f405542991a06ce9a02\n",
      "Unable recall SP2 through the first 100 retrieval results: 5abcee275542993a06baf9af\n",
      "Unable recall SP2 through the first 100 retrieval results: 5ab3c48755429969a97a81b8\n",
      "Unable recall SP1 through the first 100 retrieval results: 5a7f40055542992e7d278cc0\n",
      "Unable recall SP1 through the first 100 retrieval results: 5ab545d3554299494045ef5c\n",
      "Unable recall SP2 through the first 100 retrieval results: 5a89f58f5542992e4fca84af\n",
      "Unable recall SP2 through the first 100 retrieval results: 5a80a25d5542995d8a8ddfb7\n",
      "Unable recall SP1 through the first 100 retrieval results: 5ae1f3df554299234fd04364\n",
      "Unable recall SP2 through the first 100 retrieval results: 5a7776b955429967ab10519e\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from html import unescape\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from utils.data_utils import get_valid_links\n",
    "\n",
    "faiss.omp_set_num_threads(1)\n",
    "\n",
    "\n",
    "OBS_SIZE = 1\n",
    "RET_SIZE = 100\n",
    "HOP_MAX_STEPS = (RET_SIZE + OBS_SIZE - 1) // OBS_SIZE\n",
    "all_oracle_cmds = []\n",
    "all_oracle_steps = []\n",
    "all_programed_steps = []\n",
    "hotpot_filter = {\"term\": {\"for_hotpot\": True}}\n",
    "for q_idx, (q_id, qas) in enumerate(tqdm(samples)):\n",
    "    question, answer, sp_facts = qas\n",
    "    if len(sp_facts) < 2:\n",
    "        print(f\"less than 2 supporting facts: {q_id}\")\n",
    "    norm_sp_titles = set(unescape(t) for t in sp_facts.keys())\n",
    "    sp_ids = set(title2id[t] for t in norm_sp_titles)\n",
    "    \n",
    "    # ==================== hop 1 ====================\n",
    "    sp_ranks = {strategy: {sp_id: 2 * RET_SIZE for sp_id in sp_ids} for strategy in [\"BM25\", \"BM25+Link\", \"MDR\", \"MDR+Link\"]}\n",
    "    \n",
    "    # BM25\n",
    "    if not query_redis.exists(question):\n",
    "        query_redis.set(question, qg1.predict(question, question)[0][0].strip())\n",
    "    q1 = query_redis.get(question)\n",
    "    if not bm25_redis.exists(q1) or (bm25_redis.llen(q1) < RET_SIZE and bm25_redis.lindex(q1, -1) != 'EOL'):\n",
    "        hits = [hit['_id'] for hit in sparse_retriever.search(q1, RET_SIZE, filter_dic=hotpot_filter, n_retrieval=RET_SIZE * 2)]\n",
    "        bm25_redis.delete(q1)\n",
    "        if len(hits) < RET_SIZE:\n",
    "            bm25_redis.rpush(q1, *(hits + ['EOL']))\n",
    "        else:\n",
    "            bm25_redis.rpush(q1, *hits)\n",
    "    bm25_hits = bm25_redis.lrange(q1, 0, -1)\n",
    "    if bm25_hits[-1] == 'EOL':\n",
    "        bm25_hits = bm25_hits[:-1]\n",
    "    for p_idx, p_id in enumerate(bm25_hits[:RET_SIZE]):\n",
    "        para = corpus[p_id]\n",
    "        hyperlinks = get_valid_links(para, strict=True)\n",
    "        if p_id in sp_ids:\n",
    "            sp_ranks['BM25'][p_id] = min(p_idx, sp_ranks['BM25'][p_id])\n",
    "        for sp_title in (norm_sp_titles & set(hyperlinks.keys())):\n",
    "            sp_id = title2id[sp_title]\n",
    "            sp_ranks['BM25+Link'][sp_id] = min(p_idx, sp_ranks['BM25+Link'][sp_id])\n",
    "        if max(list(sp_ranks['BM25'].values()) + list(sp_ranks['BM25+Link'].values())) <= p_idx:\n",
    "            break\n",
    "    \n",
    "    # MDR\n",
    "    qk = questions[q_idx]\n",
    "#     if not mdr_redis.exists(qk) or (mdr_redis.llen(qk) < RET_SIZE and mdr_redis.lindex(qk, -1) != 'EOL'):\n",
    "#         hits = dense_retriever.search(questions[q_idx], max(RET_SIZE, 1000), args.max_q_len)[0]\n",
    "#         mdr_redis.delete(qk)\n",
    "#         if len(hits) < RET_SIZE:\n",
    "#             mdr_redis.rpush(qk, *(hits + ['EOL']))\n",
    "#         else:\n",
    "#             mdr_redis.rpush(qk, *hits)\n",
    "    mdr_hits = mdr_redis.lrange(qk, 0, -1)\n",
    "    if mdr_hits[-1] == 'EOL':\n",
    "        mdr_hits = mdr_hits[:-1]\n",
    "    assert len(mdr_hits) > 0\n",
    "    for p_idx, p_id in enumerate(mdr_hits[:RET_SIZE]):\n",
    "        para = corpus[p_id]\n",
    "        hyperlinks = get_valid_links(para, strict=True)\n",
    "        if p_id in sp_ids:\n",
    "            sp_ranks['MDR'][p_id] = min(p_idx, sp_ranks['MDR'][p_id])\n",
    "        for sp_title in norm_sp_titles & set(hyperlinks.keys()):\n",
    "            sp_id = title2id[sp_title]\n",
    "            sp_ranks['MDR+Link'][sp_id] = min(p_idx, sp_ranks['MDR+Link'][sp_id])\n",
    "        if max(list(sp_ranks['MDR'].values()) + list(sp_ranks['MDR+Link'].values())) <= p_idx:\n",
    "            break\n",
    "    \n",
    "    easy_steps, hard_steps = {}, {}\n",
    "    for strategy, _sp_ranks in sp_ranks.items():\n",
    "        (easy_sp_id, easy_sp_rank), (hard_sp_id, hard_sp_rank) = sorted(_sp_ranks.items(), key=lambda x: x[1])\n",
    "        easy_steps[strategy] = (easy_sp_rank + OBS_SIZE) // OBS_SIZE\n",
    "        hard_steps[strategy] = (hard_sp_rank + OBS_SIZE) // OBS_SIZE\n",
    "        if strategy.endswith('+Link'):\n",
    "            easy_steps[strategy] += 1\n",
    "            hard_steps[strategy] += 1\n",
    "    programed_steps = easy_steps.copy()\n",
    "    \n",
    "    oracle_cmds = []\n",
    "    oracle_steps = 0\n",
    "    recalled_sp_ids = []\n",
    "    if min(min(_sp_ranks.values()) for _sp_ranks in sp_ranks.values()) >= RET_SIZE:\n",
    "        print(f\"Unable recall SP1 through the first {RET_SIZE} retrieval results: {q_id}\")\n",
    "    else:\n",
    "        strategy = min(easy_steps.keys(), key=lambda k: (easy_steps[k], hard_steps[k]))\n",
    "        if strategy.endswith('+Link'):\n",
    "            oracle_cmds.append(f\"{strategy[:-5]}({repr(q1) if strategy.startswith('BM25') else '$Q'}, {OBS_SIZE * (easy_steps[strategy] - 1)})\")\n",
    "            oracle_steps += easy_steps[strategy] - 1\n",
    "            bridge_idx = min(sp_ranks[strategy].values())\n",
    "            bridge_id = bm25_hits[bridge_idx] if strategy.startswith('BM25') else mdr_hits[bridge_idx]\n",
    "            bridge_para = corpus[bridge_id]\n",
    "            tgts = set(get_valid_links(bridge_para, strict=True).keys())\n",
    "            assert len(norm_sp_titles & tgts) > 0\n",
    "            for sp_title in (norm_sp_titles & tgts):\n",
    "                oracle_cmds[-1] += f\"; [{bridge_para['title']}]({sp_title})\"\n",
    "                oracle_steps += 1\n",
    "                recalled_sp_ids.append(title2id[sp_title])\n",
    "            programed_steps[strategy] = oracle_steps\n",
    "        else:\n",
    "            oracle_cmds.append(f\"{strategy}({repr(q1) if strategy.startswith('BM25') else '$Q'}, {OBS_SIZE * easy_steps[strategy]})\")\n",
    "            oracle_steps += easy_steps[strategy]\n",
    "            recalled_sp_ids.append(min(sp_ids, key=lambda k: sp_ranks[strategy][k]))\n",
    "            if hard_steps[strategy] == easy_steps[strategy]:\n",
    "                recalled_sp_ids.append(max(sp_ids, key=lambda k: sp_ranks[strategy][k]))\n",
    "    \n",
    "    for func_name in ['BM25', 'MDR']:\n",
    "        programed_steps[func_name] = min(programed_steps[func_name], HOP_MAX_STEPS + 3)\n",
    "        programed_steps[f'{func_name}+Link'] = min(programed_steps[f'{func_name}+Link'], HOP_MAX_STEPS + 3)\n",
    "        if programed_steps[f'{func_name}+Link'] > programed_steps[func_name]:\n",
    "            programed_steps[f'{func_name}+Link'] = programed_steps[func_name]\n",
    "    programed_steps['BM25|MDR'] = programed_steps['BM25']\n",
    "    programed_steps['BM25|MDR+Link'] = programed_steps['BM25+Link']\n",
    "    if len(recalled_sp_ids) == 0 or set(recalled_sp_ids) == sp_ids:  # failed to recall SP1 or recalled the SP2 at the same time\n",
    "        oracle_cmds.append(f\"ANSWER({repr(answer) if set(recalled_sp_ids) == sp_ids else None})\")\n",
    "        all_oracle_cmds.append(oracle_cmds)\n",
    "        all_oracle_steps.append(oracle_steps)\n",
    "        all_programed_steps.append(programed_steps)\n",
    "        continue\n",
    "\n",
    "    # ==================== hop 2 ====================\n",
    "    assert len(recalled_sp_ids) == 1\n",
    "    sp1 = corpus[recalled_sp_ids[0]]\n",
    "    sp1_title = sp1['title']\n",
    "    sp2_id = (sp_ids - set(recalled_sp_ids)).pop()\n",
    "    sp2 = corpus[sp2_id]\n",
    "    norm_sp2_title = unescape(sp2['title'])\n",
    "    sp2_ranks = {strategy: 2 * RET_SIZE for strategy in [\"BM25\", \"BM25+Link\", \"MDR\", \"MDR+Link\"]}\n",
    "        \n",
    "    # BM25\n",
    "    obs = ' '.join([question, f\"<t> {sp1['title']} </t> {sp1['text'][sp1['sentence_spans'][0][0]:sp1['sentence_spans'][-1][1]]}\"])\n",
    "    if not query_redis.exists(obs):\n",
    "        query_redis.set(obs, qg2.predict(obs, question)[0][0].strip())\n",
    "    q2 = query_redis.get(obs)\n",
    "    if not bm25_redis.exists(q2) or (bm25_redis.llen(q2) < RET_SIZE and bm25_redis.lindex(q2, -1) != 'EOL'):\n",
    "        hits = [hit['_id'] for hit in sparse_retriever.search(q2, RET_SIZE, filter_dic=hotpot_filter, n_retrieval=RET_SIZE * 2)]\n",
    "        bm25_redis.delete(q2)\n",
    "        if len(hits) < RET_SIZE:\n",
    "            bm25_redis.rpush(q2, *(hits + ['EOL']))\n",
    "        else:\n",
    "            bm25_redis.rpush(q2, *hits)\n",
    "    bm25_hits = bm25_redis.lrange(q2, 0, -1)\n",
    "    if bm25_hits[-1] == 'EOL':\n",
    "        bm25_hits = bm25_hits[:-1]\n",
    "    for p_idx, p_id in enumerate(bm25_hits[:RET_SIZE]):\n",
    "        para = corpus[p_id]\n",
    "        hyperlinks = get_valid_links(para, strict=True)\n",
    "        if p_id == sp2_id:\n",
    "            sp2_ranks['BM25'] = min(p_idx, sp2_ranks['BM25'])\n",
    "        elif norm_sp2_title in hyperlinks.keys():\n",
    "            sp2_ranks['BM25+Link'] = min(p_idx, sp2_ranks['BM25+Link'])\n",
    "        if max(sp2_ranks['BM25'], sp2_ranks['BM25+Link']) <= p_idx:\n",
    "            break\n",
    "    \n",
    "    # MDR\n",
    "    qk = f\"{questions[q_idx]}\\t+++\\t{unescape(sp1['title'])}\"\n",
    "    if not mdr_redis.exists(qk) or (mdr_redis.llen(qk) < RET_SIZE and mdr_redis.lindex(qk, -1) != 'EOL'):\n",
    "        expansion = sp1['text']\n",
    "        expansion = expansion[sp1['sentence_spans'][0][0]:sp1['sentence_spans'][-1][1]]  # if strict\n",
    "        expanded_query = (questions[q_idx], expansion if expansion else sp1['title'])\n",
    "        hits = dense_retriever.search(expanded_query, max(RET_SIZE, 1000), args.max_q_sp_len)[0]\n",
    "        mdr_redis.delete(qk)\n",
    "        if len(hits) < RET_SIZE:\n",
    "            mdr_redis.rpush(qk, *(hits + ['EOL']))\n",
    "        else:\n",
    "            mdr_redis.rpush(qk, *hits)\n",
    "    mdr_hits = mdr_redis.lrange(qk, 0, -1)\n",
    "    if mdr_hits[-1] == 'EOL':\n",
    "        mdr_hits = mdr_hits[:-1]\n",
    "    assert len(mdr_hits) > 0\n",
    "    for p_idx, p_id in enumerate(mdr_hits[:RET_SIZE]):\n",
    "        para = corpus[p_id]\n",
    "        hyperlinks = get_valid_links(para, strict=True)\n",
    "        if p_id == sp2_id:\n",
    "            sp2_ranks['MDR'] = min(p_idx, sp2_ranks['BM25'])\n",
    "        elif norm_sp2_title in hyperlinks.keys():\n",
    "            sp2_ranks['MDR+Link'] = min(p_idx, sp2_ranks['BM25+Link'])\n",
    "        if max(sp2_ranks['MDR'], sp2_ranks['MDR+Link']) <= p_idx:\n",
    "            break\n",
    "    \n",
    "    sp2_steps = {}\n",
    "    for strategy, sp2_rank in sp2_ranks.items():\n",
    "        sp2_steps[strategy] = (sp2_rank + OBS_SIZE) // OBS_SIZE\n",
    "        if strategy.endswith('+Link'):\n",
    "            sp2_steps[strategy] += 1\n",
    "\n",
    "    if norm_sp2_title in set(get_valid_links(sp1, strict=True)):\n",
    "        oracle_cmds.append(f\"[{sp1_title}]({sp2['title']})\")\n",
    "        oracle_steps += 1\n",
    "        recalled_sp_ids.append(sp2_id)\n",
    "        sp2_steps['BM25+Link'] = 1\n",
    "        sp2_steps['MDR+Link'] = 1\n",
    "    else:\n",
    "        if min(sp2_ranks.values()) >= RET_SIZE:\n",
    "            print(f\"Unable recall SP2 through the first {RET_SIZE} retrieval results: {q_id}\")\n",
    "        else:\n",
    "            strategy = min(sp2_steps.keys(), key=lambda k: sp2_steps[k])\n",
    "            if strategy.endswith('+Link'):\n",
    "                oracle_cmds.append(f\"{strategy[:-5]}({repr(q2) if strategy.startswith('BM25') else ('$Q+${%s}' % sp1_title)}, {OBS_SIZE * (sp2_steps[strategy] - 1)})\")\n",
    "                oracle_steps += sp2_steps[strategy] - 1\n",
    "                bridge_idx = sp2_ranks[strategy]\n",
    "                bridge_id = bm25_hits[bridge_idx] if strategy.startswith('BM25') else mdr_hits[bridge_idx]\n",
    "                bridge_para = corpus[bridge_id]\n",
    "                tgts = set(get_valid_links(bridge_para, strict=True).keys())\n",
    "                assert norm_sp2_title in tgts\n",
    "                oracle_cmds[-1] += f\"; [{bridge_para['title']}]({sp2['title']})\"\n",
    "                oracle_steps += 1\n",
    "                recalled_sp_ids.append(sp2_id)\n",
    "            else:\n",
    "                oracle_cmds.append(f\"{strategy}({repr(q1) if strategy.startswith('BM25') else ('$Q+${%s}' % sp1_title)}, {OBS_SIZE * easy_steps[strategy]})\")\n",
    "                oracle_steps += sp2_steps[strategy]\n",
    "                recalled_sp_ids.append(sp2_id)\n",
    "    \n",
    "    oracle_cmds.append(f\"ANSWER({repr(answer) if set(recalled_sp_ids) == sp_ids else None})\")\n",
    "    for func_name in ['BM25', 'MDR']:\n",
    "        sp2_steps[func_name] = min(sp2_steps[func_name], HOP_MAX_STEPS + 2)\n",
    "        sp2_steps[f'{func_name}+Link'] = min(sp2_steps[f'{func_name}+Link'], HOP_MAX_STEPS + 2)\n",
    "        if sp2_steps[f'{func_name}+Link'] > sp2_steps[func_name]:\n",
    "            sp2_steps[f'{func_name}+Link'] = sp2_steps[func_name]\n",
    "    programed_steps['BM25|MDR'] += sp2_steps['MDR']\n",
    "    programed_steps['BM25|MDR+Link'] += sp2_steps['MDR+Link']\n",
    "    for strategy in sp2_steps.keys():\n",
    "#         if sprogramed_steps[strategy] != HOP_MAX_STEPS + 3:\n",
    "        programed_steps[strategy] += sp2_steps[strategy]\n",
    "#     programed_steps = {strategy: programed_steps[strategy] + sp2_steps[strategy] for strategy in programed_steps.keys()}\n",
    "    all_oracle_cmds.append(oracle_cmds)\n",
    "    all_oracle_steps.append(oracle_steps)\n",
    "    all_programed_steps.append(programed_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.737609723160027\n"
     ]
    }
   ],
   "source": [
    "print(sum(all_oracle_steps) / len(all_oracle_steps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'BM25': 35.009858203916274, 'BM25+Link': 17.103578663065495, 'MDR': 19.42565833896016, 'MDR+Link': 13.569615124915597, 'BM25|MDR': 16.02795408507765, 'BM25|MDR+Link': 11.039837947332883}\n"
     ]
    }
   ],
   "source": [
    "avg_programed_steps = {}\n",
    "for strategy in all_programed_steps[0].keys():\n",
    "    avg_programed_steps[strategy] = sum(programed_steps[strategy] for programed_steps in all_programed_steps) / len(all_programed_steps)\n",
    "print(avg_programed_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 2, 3, 2, 2, 2, 2, 2, 2, 2]\n",
      "[['MDR($Q, 1)', 'MDR($Q+${Ed Wood}, 1)', \"ANSWER('yes')\"], [\"BM25('Corliss Archer in the film Kiss and Tell', 1)\", '[Kiss and Tell (1945 film)](Shirley Temple)', \"ANSWER('Chief of Protocol')\"], [\"BM25('set of companion books narrating the stories of enslaved worlds and alien species', 1); [The Andalite's Gift](Animorphs)\", 'MDR($Q+${Animorphs}, 14)', \"ANSWER('Animorphs')\"], ['MDR($Q, 1)', \"BM25('Laleli Mosque', 1)\", \"ANSWER('no')\"], ['BM25(\\'The director of the romantic comedy \"Big Stone Gap\"\\', 1)', '[Big Stone Gap (film)](Adriana Trigiani)', \"ANSWER('Greenwich Village, New York City')\"], [\"BM25('2014 S/S', 1)\", '[2014 S/S](Winner (band))', \"ANSWER('YG Entertainment')\"], [\"BM25('known by his stage name Aladin', 1)\", '[Eenasul Fateh](Management consulting)', \"ANSWER('Eenasul Fateh')\"], [\"BM25('The arena where the Lewiston Maineiacs', 1)\", \"BM25('The arena where the Lewiston Maineiacs', 1)\", \"ANSWER('3,677 seated')\"], [\"BM25('Annie Morton', 1)\", '[Annie Morton](Terry Richardson)', \"ANSWER('Terry Richardson')\"], ['MDR($Q, 1)', \"BM25('Local H', 1)\", \"ANSWER('yes')\"]]\n"
     ]
    }
   ],
   "source": [
    "print(all_oracle_steps[:10])\n",
    "print(all_oracle_cmds[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3094"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([cmds for cmds in all_oracle_cmds if cmds[0].startswith('MDR(')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4262"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([cmds for cmds in all_oracle_cmds if cmds[0].startswith('BM25(')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "207"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([cmds for cmds in all_oracle_cmds if cmds[-1] == 'ANSWER(None)'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"border-collapse: collapse; border: none; border-spacing: 0px;\">\n",
    "\t<tr>\n",
    "\t\t<td style=\"border-bottom: 1px solid rgb(0, 0, 0); padding-right: 3pt; padding-left: 3pt;\">\n",
    "\t\t</td>\n",
    "\t\t<td style=\"border-bottom: 1px solid rgb(0, 0, 0); padding-right: 3pt; padding-left: 3pt;\">\n",
    "\t\t\t1\n",
    "\t\t</td>\n",
    "\t\t<td style=\"border-bottom: 1px solid rgb(0, 0, 0); padding-right: 3pt; padding-left: 3pt;\">\n",
    "\t\t\t2\n",
    "\t\t</td>\n",
    "\t\t<td style=\"border-bottom: 1px solid rgb(0, 0, 0); padding-right: 3pt; padding-left: 3pt;\">\n",
    "\t\t\t5\n",
    "\t\t</td>\n",
    "\t\t<td style=\"border-bottom: 1px solid rgb(0, 0, 0); padding-right: 3pt; padding-left: 3pt;\">\n",
    "\t\t\t10\n",
    "\t\t</td>\n",
    "\t</tr>\n",
    "\t<tr>\n",
    "\t\t<td style=\"border-top: 1px solid rgb(0, 0, 0); text-align: center; padding-right: 3pt; padding-left: 3pt;\">\n",
    "\t\t\tBM25\n",
    "\t\t</td>\n",
    "\t\t<td style=\"border-top: 1px solid rgb(0, 0, 0); text-align: right; padding-right: 3pt; padding-left: 3pt;\">\n",
    "\t\t\t35.66\n",
    "\t\t</td>\n",
    "\t\t<td style=\"border-top: 1px solid rgb(0, 0, 0); text-align: right; padding-right: 3pt; padding-left: 3pt;\">\n",
    "\t\t\t16.34\n",
    "\t\t</td>\n",
    "\t\t<td style=\"border-top: 1px solid rgb(0, 0, 0); text-align: right; padding-right: 3pt; padding-left: 3pt;\">\n",
    "\t\t\t7.14\n",
    "\t\t</td>\n",
    "\t\t<td style=\"border-top: 1px solid rgb(0, 0, 0); text-align: right; padding-right: 3pt; padding-left: 3pt;\">\n",
    "\t\t\t4.32\n",
    "\t\t</td>\n",
    "\t</tr>\n",
    "\t<tr>\n",
    "\t\t<td style=\"text-align: center; padding-right: 3pt; padding-left: 3pt;\">\n",
    "\t\t\tMDR\n",
    "\t\t</td>\n",
    "\t\t<td style=\"text-align: right; padding-right: 3pt; padding-left: 3pt;\">\n",
    "\t\t\t22.23\n",
    "\t\t</td>\n",
    "\t\t<td style=\"text-align: right; padding-right: 3pt; padding-left: 3pt;\">\n",
    "\t\t\t11.59\n",
    "\t\t</td>\n",
    "\t\t<td style=\"text-align: right; padding-right: 3pt; padding-left: 3pt;\">\n",
    "\t\t\t5.54\n",
    "\t\t</td>\n",
    "\t\t<td style=\"text-align: right; padding-right: 3pt; padding-left: 3pt;\">\n",
    "\t\t\t3.58\n",
    "\t\t</td>\n",
    "\t</tr>\n",
    "\t<tr>\n",
    "\t\t<td style=\"border-bottom: 1px solid rgb(0, 0, 0); text-align: center; padding-right: 3pt; padding-left: 3pt;\">\n",
    "\t\t\tBM25|MDR\n",
    "\t\t</td>\n",
    "\t\t<td style=\"border-bottom: 1px solid rgb(0, 0, 0); text-align: right; padding-right: 3pt; padding-left: 3pt;\">\n",
    "\t\t\t17.95\n",
    "\t\t</td>\n",
    "\t\t<td style=\"border-bottom: 1px solid rgb(0, 0, 0); text-align: right; padding-right: 3pt; padding-left: 3pt;\">\n",
    "\t\t\t9.40\n",
    "\t\t</td>\n",
    "\t\t<td style=\"border-bottom: 1px solid rgb(0, 0, 0); text-align: right; padding-right: 3pt; padding-left: 3pt;\">\n",
    "\t\t\t4.62\n",
    "\t\t</td>\n",
    "\t\t<td style=\"border-bottom: 1px solid rgb(0, 0, 0); text-align: right; padding-right: 3pt; padding-left: 3pt;\">\n",
    "\t\t\t3.08\n",
    "\t\t</td>\n",
    "\t</tr>\n",
    "\t<tr>\n",
    "\t\t<td style=\"border-top: 1px solid rgb(0, 0, 0); text-align: center; padding-right: 3pt; padding-left: 3pt;\">\n",
    "\t\t\tBM25+Link\n",
    "\t\t</td>\n",
    "\t\t<td style=\"border-top: 1px solid rgb(0, 0, 0); text-align: right; padding-right: 3pt; padding-left: 3pt;\">\n",
    "\t\t\t16.69\n",
    "\t\t</td>\n",
    "\t\t<td style=\"border-top: 1px solid rgb(0, 0, 0); text-align: right; padding-right: 3pt; padding-left: 3pt;\">\n",
    "\t\t\t7.38\n",
    "\t\t</td>\n",
    "\t\t<td style=\"border-top: 1px solid rgb(0, 0, 0); text-align: right; padding-right: 3pt; padding-left: 3pt;\">\n",
    "\t\t\t3.71\n",
    "\t\t</td>\n",
    "\t\t<td style=\"border-top: 1px solid rgb(0, 0, 0); text-align: right; padding-right: 3pt; padding-left: 3pt;\">\n",
    "\t\t\t2.62\n",
    "\t\t</td>\n",
    "\t</tr>\n",
    "\t<tr>\n",
    "\t\t<td style=\"text-align: center; padding-right: 3pt; padding-left: 3pt;\">\n",
    "\t\t\tMDR+Link\n",
    "\t\t</td>\n",
    "\t\t<td style=\"text-align: right; padding-right: 3pt; padding-left: 3pt;\">\n",
    "\t\t\t15.17\n",
    "\t\t</td>\n",
    "\t\t<td style=\"text-align: right; padding-right: 3pt; padding-left: 3pt;\">\n",
    "\t\t\t8.26\n",
    "\t\t</td>\n",
    "\t\t<td style=\"text-align: right; padding-right: 3pt; padding-left: 3pt;\">\n",
    "\t\t\t4.27\n",
    "\t\t</td>\n",
    "\t\t<td style=\"text-align: right; padding-right: 3pt; padding-left: 3pt;\">\n",
    "\t\t\t2.96\n",
    "\t\t</td>\n",
    "\t</tr>\n",
    "\t<tr>\n",
    "\t\t<td style=\"border-bottom: 1px solid rgb(0, 0, 0); text-align: center; padding-right: 3pt; padding-left: 3pt;\">\n",
    "\t\t\tBM25|MDR+Link\n",
    "\t\t</td>\n",
    "\t\t<td style=\"border-bottom: 1px solid rgb(0, 0, 0); text-align: right; padding-right: 3pt; padding-left: 3pt;\">\n",
    "\t\t\t12.00\n",
    "\t\t</td>\n",
    "\t\t<td style=\"border-bottom: 1px solid rgb(0, 0, 0); text-align: right; padding-right: 3pt; padding-left: 3pt;\">\n",
    "\t\t\t6.64\n",
    "\t\t</td>\n",
    "\t\t<td style=\"border-bottom: 1px solid rgb(0, 0, 0); text-align: right; padding-right: 3pt; padding-left: 3pt;\">\n",
    "\t\t\t3.58\n",
    "\t\t</td>\n",
    "\t\t<td style=\"border-bottom: 1px solid rgb(0, 0, 0); text-align: right; padding-right: 3pt; padding-left: 3pt;\">\n",
    "\t\t\t2.58\n",
    "\t\t</td>\n",
    "\t</tr>\n",
    "\t<tr>\n",
    "\t\t<td style=\"border-top: 1px solid rgb(0, 0, 0); text-align: center; border-bottom: 2px solid black; padding-right: 3pt; padding-left: 3pt;\">\n",
    "\t\t\toracle\n",
    "\t\t</td>\n",
    "\t\t<td style=\"border-top: 1px solid rgb(0, 0, 0); text-align: right; border-bottom: 2px solid black; padding-right: 3pt; padding-left: 3pt;\">\n",
    "\t\t\t3.79\n",
    "\t\t</td>\n",
    "\t\t<td style=\"border-top: 1px solid rgb(0, 0, 0); text-align: right; border-bottom: 2px solid black; padding-right: 3pt; padding-left: 3pt;\">\n",
    "\t\t\t2.61\n",
    "\t\t</td>\n",
    "\t\t<td style=\"border-top: 1px solid rgb(0, 0, 0); text-align: right; border-bottom: 2px solid black; padding-right: 3pt; padding-left: 3pt;\">\n",
    "\t\t\t1.97\n",
    "\t\t</td>\n",
    "\t\t<td style=\"border-top: 1px solid rgb(0, 0, 0); text-align: right; border-bottom: 2px solid black; padding-right: 3pt; padding-left: 3pt;\">\n",
    "\t\t\t1.76\n",
    "\t\t</td>\n",
    "\t</tr>\n",
    "</table>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showtags": false,
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
